Kaggle User Performance Prediction ğŸš€

Overview

This project analyzes Kaggle user engagement, competition participation, and performance using machine learning. By leveraging classification and regression models, we predict key metrics such as gold medal achievements, competition performance tiers, and dropout risks.

Objective

Predict gold medal achievements based on user competition history and engagement.
Classify users into competition performance tiers using past performance and activity levels.
Identify inactive users (dropout risk) based on engagement patterns.
Predict a user's overall performance tier based on participation across competitions, notebooks, datasets, and discussions.
Dataset

The dataset consists of Kaggle users and includes the following key features:

Key Features:
User Engagement: Competition participation, submissions, notebooks, datasets, discussions.
Performance Metrics: Medals (gold, silver, bronze), performance tiers (competitions, notebooks, datasets, discussions).
Activity Trends: Registration date, elapsed days since registration, last content shared.
Recognition Factors: Followers, upvotes received on notebooks and datasets.
Technologies Used

Programming Language: Python ğŸ
Libraries: Scikit-Learn, XGBoost, Random Forest, MLP, SVC, Decision Tree, Pandas, Matplotlib, Seaborn
Approach & Methodology

1ï¸âƒ£ Data Preprocessing & Feature Engineering
Handled missing values and outliers.
Converted categorical data using Label Encoding.
Normalized numerical features using StandardScaler for models sensitive to scale (MLP, SVC).
2ï¸âƒ£ Exploratory Data Analysis (EDA)
Visualized user activity trends (competitions, notebooks, discussions).
Analyzed correlation between performance tiers and engagement metrics.
Examined feature importance to determine key factors influencing user success.
3ï¸âƒ£ Machine Learning Models & Predictions
1. Predicting Gold Medal Achievements ğŸ…

ğŸ“Œ Target: GoldCompetitionMedals
ğŸ”¹ Features:

Competition count, submission count, performance tiers
Followers, dataset and notebook upvotes
ğŸ”¹ Models Used:
âœ… Random Forest Regressor
âœ… MLP Regressor

2. Predicting Competition Performance Tier ğŸ¯

ğŸ“Œ Target: CompetitionsPerformanceTier
ğŸ”¹ Features:

Competition participation, submissions, medals won
Performance across competitions, notebooks, datasets, discussions
ğŸ”¹ Model Used:
âœ… Support Vector Classifier (SVC)

3. Predicting User Dropout Risk (Inactive Users) ğŸ“‰

ğŸ“Œ Target: LastContentDaysElapsed (Higher value = Higher dropout risk)
ğŸ”¹ Features:

Elapsed days since registration
Competition, notebook, dataset activity
Performance tiers
ğŸ”¹ Model Used:
âœ… XGBoost Regressor

4. Predicting Overall User Performance Tier ğŸ†

ğŸ“Œ Target: PerformanceTier
ğŸ”¹ Features:

Competition, dataset, notebook, discussion performance tiers
Competitions participated in, notebooks created
ğŸ”¹ Model Used:
âœ… Decision Tree Classifier

4ï¸âƒ£ Model Optimization & Evaluation
Each model was optimized using hyperparameter tuning and evaluated with relevant metrics:
âœ… Regression Models: Evaluated using MAE, RMSE, RÂ² Score
âœ… Classification Models: Evaluated using Accuracy, Precision, Recall, F1-Score

Results & Insights

ğŸ“Œ Gold Medal Prediction: More competitions and high submission counts significantly impact medal achievements.
ğŸ“Œ Performance Tier Classification: Medal count and submission frequency are strong indicators of competition success.
ğŸ“Œ User Dropout Prediction: Less engagement in notebooks/datasets and long inactivity periods increase dropout risk.
ğŸ“Œ Feature Importance Analysis: Competition history, performance tiers, and engagement levels are key predictors.
